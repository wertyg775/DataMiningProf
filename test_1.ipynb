{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7874a62-39ae-421f-89fb-5e4405485dbd",
   "metadata": {
    "id": "e7874a62-39ae-421f-89fb-5e4405485dbd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1614428-16ff-435e-8b16-a398d21ea30a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1614428-16ff-435e-8b16-a398d21ea30a",
    "outputId": "f0eb7676-ed3e-4667-a7d0-9da635a233c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\online-retail-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/online-retail-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "FU604DAlpy9U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU604DAlpy9U",
    "outputId": "32a7fedd-244c-4e37-f327-66f27f8d2180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['online_retail_II.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# List files to find the correct CSV name\n",
    "files = os.listdir(path)\n",
    "print(\"Files in directory:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tJnVohJTqWyN",
   "metadata": {
    "id": "tJnVohJTqWyN"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(path + \"/online_retail_II.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85127642-94d6-4621-8e42-1ad25afb7b73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85127642-94d6-4621-8e42-1ad25afb7b73",
    "outputId": "43ac1be1-46af-4e7c-9cd8-e283fd426546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525461, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084408b2-0ec1-4842-acee-160941ad096b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "084408b2-0ec1-4842-acee-160941ad096b",
    "outputId": "cf86520f-ac31-44e1-a7c1-166c6505ee1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(n=5000)\n",
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3290bf-15f2-4b65-bf0e-649dc5cc678c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c3290bf-15f2-4b65-bf0e-649dc5cc678c",
    "outputId": "da9f5482-4f2d-410f-e2ae-b8ebef561fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
       "       'Price', 'Customer ID', 'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2bad9f-d7d0-41da-9499-e2e2be1b07eb",
   "metadata": {
    "id": "fb2bad9f-d7d0-41da-9499-e2e2be1b07eb"
   },
   "outputs": [],
   "source": [
    "df_sample = df_sample.dropna(subset=['Customer ID', 'Price', 'Quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64355cf4-dbce-44e7-860c-84e5a3733847",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64355cf4-dbce-44e7-860c-84e5a3733847",
    "outputId": "10d060f0-70b7-4be5-c091-43b91f738eba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metadata loaded from file.\n",
      "Trained model loaded from file. Skipping training phase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python313\\Lib\\site-packages\\sdv\\_utils.py:500: FutureWarning:\n",
      "\n",
      "The 'load' function will be deprecated in future versions of SDV. Please use 'utils.load_synthesizer' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "\n",
    "# Define file paths\n",
    "METADATA_FILE = 'metadata.json'\n",
    "MODEL_FILE = 'my_ctgan_model.pkl'\n",
    "cols_to_model = ['Quantity', 'Price', 'Country']\n",
    "\n",
    "# 1. Handle Metadata\n",
    "if os.path.exists(METADATA_FILE):\n",
    "    metadata = Metadata.load_from_json(METADATA_FILE)\n",
    "    print(\"✓ Metadata loaded from file.\")\n",
    "else:\n",
    "    # Detect and save if it doesn't exist\n",
    "    df_for_ctgan = df_sample[cols_to_model].copy()\n",
    "    metadata = Metadata.detect_from_dataframe(data=df_for_ctgan, table_name='retail_patterns')\n",
    "    metadata.save_to_json(METADATA_FILE)\n",
    "    print(\"! Metadata detected and saved.\")\n",
    "\n",
    "# 2. Handle the Trained Model\n",
    "if os.path.exists(MODEL_FILE):\n",
    "    # Load the pre-trained synthesizer\n",
    "    synthesizer = CTGANSynthesizer.load(MODEL_FILE)\n",
    "    print(\"Trained model loaded from file. Skipping training phase.\")\n",
    "else:\n",
    "    # Initialize and train if no model is found\n",
    "    print(\"No model found. Starting training (this may take a few minutes)...\")\n",
    "    synthesizer = CTGANSynthesizer(\n",
    "        metadata,\n",
    "        epochs=100,\n",
    "        cuda=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    synthesizer.fit(df_sample[cols_to_model])\n",
    "    # Save the model so you don't have to train again\n",
    "    synthesizer.save(MODEL_FILE)\n",
    "    print(f\"Training complete. Model saved to {MODEL_FILE}.\")\n",
    "\n",
    "# 3. Generate 1,000 numerical/country records\n",
    "# This works instantly once the model is loaded or trained\n",
    "df_numerical_sim = synthesizer.sample(num_rows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a958ea3-47cc-4316-8f14-6be9dd7b43c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical_sim.head()\n",
    "len(df_numerical_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ef82dc-8bb4-4620-9393-d3dec04bdfb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35ef82dc-8bb4-4620-9393-d3dec04bdfb1",
    "outputId": "711b910f-338b-4492-daf3-784208b3b018",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing with Gemini 2.5 Flash...\n",
      "Processing batch 1 (rows 0-19)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 2 (rows 20-39)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 3 (rows 40-59)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 4 (rows 60-79)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 5 (rows 80-99)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 6 (rows 100-119)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 7 (rows 120-139)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 8 (rows 140-159)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 9 (rows 160-179)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 10 (rows 180-199)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 11 (rows 200-219)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 12 (rows 220-239)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 13 (rows 240-259)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 14 (rows 260-279)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 15 (rows 280-299)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 16 (rows 300-319)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 17 (rows 320-339)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 18 (rows 340-359)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 19 (rows 360-379)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 20 (rows 380-399)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 21 (rows 400-419)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 22 (rows 420-439)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 23 (rows 440-459)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 24 (rows 460-479)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 25 (rows 480-499)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 26 (rows 500-519)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 27 (rows 520-539)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 28 (rows 540-559)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 29 (rows 560-579)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 30 (rows 580-599)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 31 (rows 600-619)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 32 (rows 620-639)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 33 (rows 640-659)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 34 (rows 660-679)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 35 (rows 680-699)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 36 (rows 700-719)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 37 (rows 720-739)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 38 (rows 740-759)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 39 (rows 760-779)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 40 (rows 780-799)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 41 (rows 800-819)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 42 (rows 820-839)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 43 (rows 840-859)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 44 (rows 860-879)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 45 (rows 880-899)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 46 (rows 900-919)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 47 (rows 920-939)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 48 (rows 940-959)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 49 (rows 960-979)...\n",
      "✓ Successfully processed 20 records\n",
      "Processing batch 50 (rows 980-999)...\n",
      "✓ Successfully processed 20 records\n",
      "\n",
      "============================================================\n",
      "Processing Complete!\n",
      "============================================================\n",
      "Total rows: 1000\n",
      "Successful: 1000\n",
      "Errors: 0\n",
      "\n",
      "Sample output:\n",
      "   Quantity  Price      Country  \\\n",
      "0        11  11.29  Switzerland   \n",
      "1        12   6.50       France   \n",
      "2        16   1.45       Greece   \n",
      "\n",
      "                                         Description  \\\n",
      "0  Premium Arabica Coffee Beans, 11oz pack, rich ...   \n",
      "1               Organic Green Tea Bags, 12-count box   \n",
      "2             Multi-purpose Cleaning Cloths, 16-pack   \n",
      "\n",
      "                                              Review  \n",
      "0  These coffee beans are fantastic! Got 11. Arom...  \n",
      "1  Great organic green tea! Purchased 12 boxes at...  \n",
      "2  These cleaning cloths are a steal! Got 16 for ...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "def process_in_batches_gemini(df, batch_size=20):\n",
    "    all_results = []\n",
    "    \n",
    "    # Use Gemini 2.5 Flash - the latest and most capable Flash model\n",
    "    model = genai.GenerativeModel(\n",
    "        'gemini-2.5-flash',  # Latest Flash model\n",
    "        generation_config=genai.types.GenerationConfig(\n",
    "            temperature=0.7,\n",
    "            max_output_tokens=8192,\n",
    "            response_mime_type=\"application/json\"  # Strict JSON mode\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i : i + batch_size]\n",
    "        context_list = [\n",
    "            {\"index\": idx, \"quantity\": row['Quantity'], \"price\": row['Price']} \n",
    "            for idx, (_, row) in enumerate(batch.iterrows())\n",
    "        ]\n",
    "        \n",
    "        # Structured prompt for Gemini 2.5\n",
    "        prompt = f\"\"\"Generate exactly {len(batch)} retail transaction records.\n",
    "\n",
    "Input context: {json.dumps(context_list)}\n",
    "\n",
    "Return a JSON array with this structure:\n",
    "[\n",
    "  {{\"Description\": \"product name and details\", \"Review\": \"customer review\"}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Requirements:\n",
    "- Exactly {len(batch)} objects in the array\n",
    "- Each Description: 30-60 characters\n",
    "- Each Review: 50-100 characters\n",
    "- Make reviews realistic and varied\n",
    "- Base quantity and price mentions on the input context\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"Processing batch {i//batch_size + 1} (rows {i}-{i+len(batch)-1})...\")\n",
    "            \n",
    "            response = model.generate_content(prompt)\n",
    "            content = response.text.strip()\n",
    "            \n",
    "            # Gemini 2.5 with JSON MIME type should return clean JSON\n",
    "            if content.startswith('```'):\n",
    "                content = content.split('```')[1]\n",
    "                if content.startswith('json'):\n",
    "                    content = content[4:]\n",
    "                content = content.strip()\n",
    "            \n",
    "            batch_data = json.loads(content)\n",
    "            \n",
    "            # Handle wrapped responses\n",
    "            if isinstance(batch_data, dict):\n",
    "                if 'transactions' in batch_data:\n",
    "                    batch_data = batch_data['transactions']\n",
    "                elif 'records' in batch_data:\n",
    "                    batch_data = batch_data['records']\n",
    "                else:\n",
    "                    # Get first list value\n",
    "                    for value in batch_data.values():\n",
    "                        if isinstance(value, list):\n",
    "                            batch_data = value\n",
    "                            break\n",
    "            \n",
    "            # Validate count\n",
    "            if len(batch_data) != len(batch):\n",
    "                print(f\"⚠ Warning: Expected {len(batch)}, got {len(batch_data)} records\")\n",
    "                # Pad or trim\n",
    "                while len(batch_data) < len(batch):\n",
    "                    batch_data.append({\n",
    "                        'Description': 'Generated placeholder', \n",
    "                        'Review': 'Additional record needed'\n",
    "                    })\n",
    "                batch_data = batch_data[:len(batch)]\n",
    "            \n",
    "            all_results.extend(batch_data)\n",
    "            print(f\"✓ Successfully processed {len(batch_data)} records\")\n",
    "            \n",
    "            # Gemini 2.5 Flash has improved rate limits\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"✗ JSON parsing error in batch {i}: {e}\")\n",
    "            print(f\"Response length: {len(content)} chars\")\n",
    "            print(f\"First 300 chars: {content[:300]}\")\n",
    "            print(f\"Last 300 chars: {content[-300:]}\")\n",
    "            \n",
    "            # Try to salvage\n",
    "            try:\n",
    "                last_complete = content.rfind('}')\n",
    "                if last_complete > 0:\n",
    "                    fixed_content = content[:last_complete + 1] + ']'\n",
    "                    batch_data = json.loads(fixed_content)\n",
    "                    \n",
    "                    if isinstance(batch_data, dict):\n",
    "                        batch_data = list(batch_data.values())[0] if batch_data.values() else []\n",
    "                    \n",
    "                    recovered = len(batch_data)\n",
    "                    print(f\"  ↳ Recovered {recovered}/{len(batch)} records\")\n",
    "                    all_results.extend(batch_data)\n",
    "                    \n",
    "                    # Fill missing\n",
    "                    missing = len(batch) - recovered\n",
    "                    if missing > 0:\n",
    "                        all_results.extend([\n",
    "                            {'Description': 'Recovery incomplete', 'Review': 'Partial data'}\n",
    "                        ] * missing)\n",
    "                else:\n",
    "                    raise ValueError(\"No complete objects found\")\n",
    "                    \n",
    "            except Exception as recovery_error:\n",
    "                print(f\"  ↳ Recovery failed: {recovery_error}\")\n",
    "                all_results.extend([\n",
    "                    {'Description': 'Parse error', 'Review': 'JSON incomplete'}\n",
    "                ] * len(batch))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Unexpected error in batch {i}: {type(e).__name__}: {e}\")\n",
    "            all_results.extend([\n",
    "                {'Description': 'Generation error', 'Review': 'Request failed'}\n",
    "            ] * len(batch))\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Process with Gemini 2.5 Flash\n",
    "print(\"Starting batch processing with Gemini 2.5 Flash...\")\n",
    "df_text = process_in_batches_gemini(df_numerical_sim, batch_size=20)\n",
    "\n",
    "# Join results\n",
    "df_final = pd.concat([df_numerical_sim.reset_index(drop=True), df_text], axis=1)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Processing Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total rows: {len(df_final)}\")\n",
    "print(f\"Successful: {len(df_final[~df_final['Description'].str.contains('error|Error|incomplete|Incomplete', case=False, na=False)])}\")\n",
    "print(f\"Errors: {len(df_final[df_final['Description'].str.contains('error|Error|incomplete|Incomplete', case=False, na=False)])}\")\n",
    "print(f\"\\nSample output:\")\n",
    "print(df_final.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2288ce47-9b2e-4b74-976f-7069d2c7062b",
   "metadata": {
    "id": "2288ce47-9b2e-4b74-976f-7069d2c7062b"
   },
   "outputs": [],
   "source": [
    "# 3. Save as the final simulated dataset (Satisfies Deliverable 2)\n",
    "df_final.to_csv(\"simulated_business_records.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df8bab-35ec-4c05-88d9-b1c3416c2cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03658d01-a2b2-4e50-b842-aef8e7bb412f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
